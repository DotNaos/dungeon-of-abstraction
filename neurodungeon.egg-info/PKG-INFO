Metadata-Version: 2.4
Name: neurodungeon
Version: 0.2.0
Summary: Reference implementation of the NeuroDungeon protocol
Author-email: OpenAI <noreply@example.com>
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: hypothesis>=6.135.9
Requires-Dist: jinja2
Requires-Dist: mypy>=1.16.0
Requires-Dist: openai>=1.86.0
Requires-Dist: pytest>=8.4.0
Requires-Dist: pytest-mock>=3.14.1
Requires-Dist: pyyaml>=6.0.2
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-mock; extra == "dev"
Requires-Dist: hypothesis; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Provides-Extra: llm
Requires-Dist: openai<2,>=1; extra == "llm"
Requires-Dist: pyyaml; extra == "llm"
Dynamic: license-file

# NeuroDungeon

`neurodungeon` is a reference implementation of the NeuroDungeon Protocol v0.2.

## Installation

```bash
pip install -e .
# for development with optional LLM features
pip install -e .[dev,llm]
```

`jinja2` is installed by default so report generation works out of the box.

## Usage

Run the demo script:

```bash
python demo_neurodungeon.py
```

You can also invoke the stubbed CLI directly and choose where artifacts are stored:

```bash
neurodungeon --goal "build a web app" --persist-dir runs --enemies 2
```
After the run completes the CLI prints

```
Run cli_run complete — log: /abs/path/to/runs/cli_run/log.jsonl
```
with the absolute path to the `log.jsonl` file for easy inspection.

### Running with real LLMs

Install the dev and LLM extras then set `OPENAI_API_KEY` (and optionally
`OPENAI_MODEL`):

```bash
pip install -e .[dev,llm]
export OPENAI_API_KEY=sk-...
neurodungeon --goal "build a web app" --persist-dir runs --config dungeon.yml
```

The LLM-backed agents will use these credentials to generate artifacts.

### Dungeon config

Provide a YAML file to control lives and floors:

```yaml
lives: 3
llm_call_limit: 20
floors: [1, 2]
```

Invoke with `--config dungeon.yml` to override CLI flags. See
`examples/basic.yml` for a ready-to-use template.

## Extending

Implement custom `Player`, `Enemy`, and `Boss` agents and create an
`Orchestrator` with a nested list of enemies per floor:

```python
enemies_per_floor = [[Enemy1(), Enemy2()], [Enemy3()], ...]
orch = Orchestrator(player, enemies_per_floor, boss)
result = orch.run("build a web app", RunConfig(run_id="my_run"))
```

The orchestrator compares the number of rejections on a floor against a
threshold. If ``rejection_thresh`` is greater than ``0`` that value is used
directly. Passing ``rejection_thresh=0`` enables the dynamic rule
``ceil(E * 0.5)`` where ``E`` is the number of enemies on the floor.
If the threshold is met, one life is lost. Hints gathered on each floor are always passed to
the next `Player.act()` call, even if the floor was accepted. The
`llm_call_limit` is inclusive, so a value of `50` allows exactly 50
calls. Only one attempt is made per floor. `persist_dir` may be an
absolute path—in all cases the `run_id` is nested inside it.

### Design Rationale

Limiting to a single attempt per floor keeps the number of LLM calls and
token usage predictable, which is critical when runs are chained or
budgeted.

### Building a wheel

To create a distributable wheel for local testing:

```bash
python -m build
```
